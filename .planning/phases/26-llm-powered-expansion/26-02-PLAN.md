---
phase: 26-llm-powered-expansion
plan: 02
type: execute
wave: 2
depends_on: ["26-01"]
files_modified:
  - modules/AppVideoWizard/app/Services/LLMExpansionService.php
  - tests/Unit/VideoWizard/LLMExpansionServiceTest.php
autonomous: true

must_haves:
  truths:
    - "Complex shots are expanded using LLM with vocabulary constraints"
    - "LLM-expanded prompts contain ONLY vocabulary from existing services (no invented terms)"
    - "Non-complex shots bypass LLM and use template-based expansion"
    - "LLM failures gracefully fall back to template expansion"
  artifacts:
    - path: "modules/AppVideoWizard/app/Services/LLMExpansionService.php"
      provides: "LLM expansion orchestration with vocabulary constraints"
      exports: ["expand", "expandWithCache"]
      min_lines: 250
    - path: "tests/Unit/VideoWizard/LLMExpansionServiceTest.php"
      provides: "Unit tests for LLM expansion"
      min_lines: 120
  key_links:
    - from: "LLMExpansionService"
      to: "ComplexityDetectorService"
      via: "Complexity check before expansion"
      pattern: "complexityDetector->calculateComplexity"
    - from: "LLMExpansionService"
      to: "GrokService"
      via: "Primary LLM provider"
      pattern: "grokService->chat"
    - from: "LLMExpansionService"
      to: "CinematographyVocabulary"
      via: "Vocabulary constraints for system prompt"
      pattern: "CinematographyVocabulary"
---

<objective>
Create LLMExpansionService for AI-powered prompt expansion with vocabulary constraints.

Purpose: Expand complex shots using LLM while maintaining Hollywood vocabulary consistency. Uses meta-prompting (vocabulary constraints) instead of few-shot examples for better consistency.

Output: LLMExpansionService.php with unit tests, implementing Grok primary / Gemini fallback / Template fallback cascade.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/26-llm-powered-expansion/26-RESEARCH.md
@.planning/phases/26-llm-powered-expansion/26-01-SUMMARY.md

# Existing services to integrate
@modules/AppVideoWizard/app/Services/CinematographyVocabulary.php
@modules/AppVideoWizard/app/Services/CharacterPsychologyService.php
@modules/AppVideoWizard/app/Services/CharacterDynamicsService.php
@modules/AppVideoWizard/app/Services/PromptExpanderService.php
@app/Services/GrokService.php
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create LLMExpansionService</name>
  <files>modules/AppVideoWizard/app/Services/LLMExpansionService.php</files>
  <action>
Create LLMExpansionService that orchestrates LLM-powered expansion with vocabulary constraints.

CORE ARCHITECTURE:
1. Check complexity via ComplexityDetectorService
2. If NOT complex -> return template-based expansion (delegate to PromptExpanderService rules)
3. If complex -> attempt LLM expansion with vocabulary constraints

THREE-LAYER PROMPT CACHING (from research):
- Layer 1: System prompt (stable vocabulary) - cached by LLM provider
- Layer 2: Session context (project settings) - semi-stable
- Layer 3: Shot data (dynamic) - never cached

SYSTEM PROMPT STRUCTURE (meta-prompting, NOT few-shot):
```
You are a Hollywood cinematographer expanding video prompts. You MUST use ONLY the vocabulary provided below.

## VOCABULARY CONSTRAINTS (Use these exact terms)

### Lens Psychology
{formatted LENS_PSYCHOLOGY from CinematographyVocabulary}

### Lighting Ratios
{formatted LIGHTING_RATIOS from CinematographyVocabulary}

### Emotion Physical Manifestations (NOT emotion labels)
{formatted EMOTION_MANIFESTATIONS from CharacterPsychologyService}

### Multi-Character Spatial Dynamics
{formatted PROXEMIC_ZONES and POWER_POSITIONING from CharacterDynamicsService}

## OUTPUT FORMAT
Use semantic markers for structure:
- [LENS:] for lens/camera description
- [LIGHTING:] for lighting ratios and mood
- [FRAME:] for framing and composition
- [SUBJECT:] for character description with physical manifestations
- [DYNAMICS:] for multi-character spatial relationships
- [ENVIRONMENT:] for mise-en-scene

## CRITICAL RULES
1. NEVER use emotion labels ("angry", "sad"). Use ONLY physical manifestations.
2. NEVER invent technical terms. Use ONLY the vocabulary provided.
3. Keep expanded prompt under 200 words.
4. Multi-character scenes MUST include explicit spatial relationships from DYNAMICS vocabulary.
5. Output ONLY the expanded prompt. No explanations.
```

FALLBACK CASCADE:
1. Try Grok (grok-4-fast, $0.20/1M input, temperature 0.4)
2. On Grok failure -> Try Gemini via AIService
3. On Gemini failure -> Use PromptExpanderService::expandWithRules()

METHODS TO IMPLEMENT:
```php
public function expand(array $shotData): array
// Main entry point - checks complexity, routes accordingly
// Returns: ['expanded_prompt' => string, 'method' => 'llm'|'template', 'provider' => string, 'complexity' => array]

public function expandWithCache(array $shotData): array
// Wraps expand() with Laravel Cache (24h TTL, key = md5 of shotData)

protected function buildSystemPrompt(): string
// Builds vocabulary-constrained system prompt (STABLE for caching)

protected function buildUserPrompt(array $shotData): string
// Builds dynamic per-shot prompt

protected function expandWithGrok(array $shotData): ?array
protected function expandWithGemini(array $shotData): ?array
protected function fallbackToTemplate(array $shotData): array

protected function formatVocabulary(array $vocabulary): string
// Formats vocabulary arrays for system prompt

protected function postProcess(array $result, array $shotData): array
// Validates LLM output contains expected markers, within word limit
```

INJECT DEPENDENCIES:
- ComplexityDetectorService
- CinematographyVocabulary
- CharacterPsychologyService
- CharacterDynamicsService
- PromptExpanderService (for template fallback)
- GrokService
- AIService (for Gemini fallback)

LLM CALL PARAMETERS:
- Grok: model='grok-4-fast', temperature=0.4, max_tokens=400
- Gemini: Use AIService::processWithOverride() with 'gemini' provider

POST-PROCESSING:
- Validate prompt contains at least 2 semantic markers ([LENS:], [SUBJECT:], etc.)
- Trim to 200 words if exceeded
- Log warning if LLM ignored vocabulary constraints
  </action>
  <verify>Run `php artisan tinker` and test:
```php
$service = app(\Modules\AppVideoWizard\Services\LLMExpansionService::class);
// Test with complex shot
$result = $service->expand([
    'characters' => [['name' => 'Marcus'], ['name' => 'Elena']],
    'shot_type' => 'two-shot',
    'emotion' => 'tension',
    'subtext' => 'Hidden agenda beneath calm facade',
    'environment' => 'dimly lit office'
]);
var_dump($result['method']); // 'llm' (if providers available) or 'template' (fallback)
var_dump(str_contains($result['expanded_prompt'], '[')); // true (has semantic markers)
```</verify>
  <done>LLMExpansionService routes complex shots to LLM, uses vocabulary constraints, falls back gracefully</done>
</task>

<task type="auto">
  <name>Task 2: Create LLMExpansionService unit tests</name>
  <files>tests/Unit/VideoWizard/LLMExpansionServiceTest.php</files>
  <action>
Create unit tests for LLMExpansionService.

TEST CASES:
1. **test_simple_shot_uses_template** - Non-complex shot bypasses LLM, uses template method
2. **test_complex_shot_attempts_llm** - Complex shot attempts LLM expansion
3. **test_system_prompt_contains_vocabulary** - System prompt includes LENS_PSYCHOLOGY, EMOTION_MANIFESTATIONS, PROXEMIC_ZONES
4. **test_system_prompt_contains_rules** - System prompt includes "NEVER use emotion labels" rule
5. **test_fallback_on_grok_failure** - Grok exception triggers Gemini attempt
6. **test_fallback_to_template_on_all_failure** - Both LLM failures fall back to template
7. **test_cache_hit_returns_cached** - expandWithCache returns cached result on second call
8. **test_post_processing_validates_markers** - Post-processing checks for semantic markers
9. **test_post_processing_trims_long_output** - Output over 200 words is trimmed
10. **test_multi_character_shot_includes_dynamics** - Multi-character shots include [DYNAMICS:] marker requirement

MOCKING STRATEGY:
- Mock GrokService to control success/failure scenarios
- Mock AIService for Gemini fallback testing
- Use real ComplexityDetectorService (tested in 26-01)
- Use real vocabulary services (stable, no external deps)

Use PHPUnit with `#[Test]` attributes.
  </action>
  <verify>Run `php artisan test --filter=LLMExpansionServiceTest` - all tests pass</verify>
  <done>10+ unit tests pass covering LLM routing, fallback cascade, and vocabulary constraints</done>
</task>

</tasks>

<verification>
1. Complex shots route to LLM expansion
2. Simple shots bypass LLM, use template expansion
3. System prompt contains vocabulary from all services (lens, lighting, emotions, dynamics)
4. LLM failures cascade: Grok -> Gemini -> Template
5. Cached results returned on repeat calls
6. All unit tests pass
</verification>

<success_criteria>
- LLMExpansionService::expand routes based on complexity score
- System prompt uses meta-prompting with vocabulary constraints (NOT few-shot)
- Fallback cascade works: Grok -> Gemini -> Template (never blocks)
- expandWithCache correctly caches with 24h TTL
- Expanded prompts contain semantic markers from Hollywood vocabulary
- All unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/26-llm-powered-expansion/26-02-SUMMARY.md`
</output>
