---
phase: 26-llm-powered-expansion
plan: 03
type: execute
wave: 3
depends_on: ["26-02"]
files_modified:
  - modules/AppVideoWizard/app/Services/StructuredPromptBuilderService.php
  - tests/Feature/VideoWizard/LLMExpansionIntegrationTest.php
autonomous: true

must_haves:
  truths:
    - "Complex shots in prompt building flow automatically trigger LLM expansion"
    - "LLM-expanded prompts maintain same structure as template prompts (semantic markers)"
    - "ModelPromptAdapterService processes LLM output for token limits"
    - "Simple shots continue using existing template path (no regression)"
  artifacts:
    - path: "modules/AppVideoWizard/app/Services/StructuredPromptBuilderService.php"
      provides: "LLM expansion integration in prompt building"
      contains: "LLMExpansionService"
    - path: "tests/Feature/VideoWizard/LLMExpansionIntegrationTest.php"
      provides: "End-to-end integration tests"
      min_lines: 80
  key_links:
    - from: "StructuredPromptBuilderService"
      to: "LLMExpansionService"
      via: "Complexity-based routing in buildHollywoodPrompt"
      pattern: "llmExpansionService->expand"
    - from: "LLMExpansionService output"
      to: "ModelPromptAdapterService"
      via: "Token adaptation after expansion"
      pattern: "modelPromptAdapter->adaptPromptForModel"
---

<objective>
Integrate LLMExpansionService into the prompt building pipeline.

Purpose: Wire LLM expansion into StructuredPromptBuilderService so complex shots automatically get AI enhancement while simple shots continue using efficient template expansion.

Output: Modified StructuredPromptBuilderService with LLM routing, integration tests proving end-to-end flow.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/26-llm-powered-expansion/26-RESEARCH.md
@.planning/phases/26-llm-powered-expansion/26-01-SUMMARY.md
@.planning/phases/26-llm-powered-expansion/26-02-SUMMARY.md

# Service to modify
@modules/AppVideoWizard/app/Services/StructuredPromptBuilderService.php
@modules/AppVideoWizard/app/Services/ModelPromptAdapterService.php
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate LLMExpansionService into StructuredPromptBuilderService</name>
  <files>modules/AppVideoWizard/app/Services/StructuredPromptBuilderService.php</files>
  <action>
Modify StructuredPromptBuilderService to route complex shots through LLM expansion.

INTEGRATION POINT:
The `buildHollywoodPrompt()` method is the main entry point. Add LLM routing BEFORE template-based prompt assembly.

MODIFICATION STEPS:

1. **Add LLMExpansionService injection**:
```php
protected ?LLMExpansionService $llmExpansionService = null;

public function __construct(/* existing deps */)
{
    // ... existing
    $this->llmExpansionService = app(LLMExpansionService::class);
}
```

2. **Add method to check if LLM expansion should be used**:
```php
protected function shouldUseLLMExpansion(array $options): bool
{
    // Check if LLM expansion is enabled (could be a setting)
    $llmEnabled = $options['llm_expansion'] ?? true;
    if (!$llmEnabled) return false;

    // Build shot data from options for complexity check
    $shotData = $this->buildShotDataFromOptions($options);

    return $this->llmExpansionService->isComplex($shotData);
}

protected function buildShotDataFromOptions(array $options): array
{
    return [
        'characters' => $options['characters'] ?? [],
        'shot_type' => $options['shot_type'] ?? 'medium',
        'emotion' => $options['emotion'] ?? null,
        'emotions' => $options['emotions'] ?? [],
        'subtext' => $options['subtext'] ?? '',
        'tension_level' => $options['tension_level'] ?? 5,
        'environment' => $options['environment'] ?? '',
        'relationship' => $options['relationship'] ?? null,
    ];
}
```

3. **Modify buildHollywoodPrompt to check complexity first**:
```php
public function buildHollywoodPrompt(array $options = []): array
{
    // NEW: Check if this shot is complex and should use LLM
    if ($this->shouldUseLLMExpansion($options)) {
        $shotData = $this->buildShotDataFromOptions($options);
        $llmResult = $this->llmExpansionService->expandWithCache($shotData);

        if ($llmResult['method'] === 'llm') {
            // LLM expansion succeeded - wrap in standard structure
            return $this->wrapLLMResult($llmResult, $options);
        }
        // LLM failed, fall through to template expansion
    }

    // EXISTING: Template-based prompt assembly
    // ... rest of existing code unchanged
}

protected function wrapLLMResult(array $llmResult, array $options): array
{
    // Structure LLM output to match template output format
    return [
        'prompt' => $llmResult['expanded_prompt'],
        'method' => 'llm_expansion',
        'provider' => $llmResult['provider'] ?? 'unknown',
        'complexity' => $llmResult['complexity'] ?? [],
        'shot_type' => $options['shot_type'] ?? 'medium',
        'components' => [
            'source' => 'llm_expansion',
            'fallback_used' => $llmResult['method'] === 'template',
        ],
    ];
}
```

4. **Add option to disable LLM expansion**:
Allow `'llm_expansion' => false` in options to bypass LLM for testing or performance.

IMPORTANT:
- Do NOT modify existing template logic - LLM is an ADDITION, not a replacement
- Template path remains default for simple shots
- LLM output still goes through ModelPromptAdapterService for token limits (already called in existing flow)
  </action>
  <verify>Run `php artisan tinker` and test:
```php
$builder = app(\Modules\AppVideoWizard\Services\StructuredPromptBuilderService::class);
// Simple shot - should use template
$simple = $builder->buildHollywoodPrompt(['shot_type' => 'close-up', 'emotion' => 'grief']);
var_dump($simple['method'] ?? 'template'); // 'template' or no method key
// Complex shot - should attempt LLM
$complex = $builder->buildHollywoodPrompt([
    'shot_type' => 'two-shot',
    'characters' => [['name' => 'A'], ['name' => 'B'], ['name' => 'C']],
    'subtext' => 'Hidden tension'
]);
var_dump($complex['method']); // 'llm_expansion' or 'template' if LLM unavailable
```</verify>
  <done>StructuredPromptBuilderService routes complex shots to LLM, simple shots use templates</done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests</name>
  <files>tests/Feature/VideoWizard/LLMExpansionIntegrationTest.php</files>
  <action>
Create feature-level integration tests for the complete LLM expansion flow.

TEST CASES:
1. **test_simple_shot_uses_template_path** - Single character close-up uses template, no LLM call
2. **test_complex_shot_triggers_llm_path** - 3+ characters triggers LLM expansion attempt
3. **test_llm_output_contains_hollywood_vocabulary** - LLM result contains semantic markers [LENS:], [SUBJECT:]
4. **test_llm_disabled_option_bypasses_complexity_check** - `llm_expansion => false` skips LLM
5. **test_llm_failure_fallback_produces_valid_prompt** - LLM failures still produce usable prompt
6. **test_multi_character_prompt_contains_dynamics** - Multi-character shots include spatial dynamics
7. **test_end_to_end_image_generation_flow** - Full flow from shot data to final adapted prompt

MOCKING STRATEGY:
For reliable tests, mock GrokService and AIService to control LLM responses.
Use real complexity detection and vocabulary services.

For test_llm_output_contains_hollywood_vocabulary:
- Mock GrokService to return a response WITH expected markers
- Verify markers appear in final output

For test_llm_failure_fallback_produces_valid_prompt:
- Mock GrokService to throw exception
- Mock AIService to throw exception
- Verify template fallback produces valid prompt structure

Use `RefreshDatabase` trait if needed.
Use PHPUnit with `#[Test]` attributes.
  </action>
  <verify>Run `php artisan test --filter=LLMExpansionIntegrationTest` - all tests pass</verify>
  <done>7+ integration tests pass covering complete prompt building flow with LLM expansion</done>
</task>

</tasks>

<verification>
1. buildHollywoodPrompt checks complexity before building
2. Complex shots (3+ characters, subtext) attempt LLM expansion
3. Simple shots skip LLM, use existing template path
4. LLM output wrapped in standard structure matching template output
5. Option to disable LLM expansion works
6. All integration tests pass
7. No regression in existing prompt building for simple shots
</verification>

<success_criteria>
- Complex shots automatically route to LLM expansion
- Simple shots continue using template path (no performance regression)
- LLM-expanded prompts match output structure of template prompts
- `llm_expansion => false` option disables LLM routing
- Fallback to template on LLM failure produces valid prompt
- All integration tests pass
- Success criteria from ROADMAP met:
  - "Complex shots trigger LLM expansion"
  - "LLM-expanded prompts maintain template structure and vocabulary"
</success_criteria>

<output>
After completion, create `.planning/phases/26-llm-powered-expansion/26-03-SUMMARY.md`
</output>
