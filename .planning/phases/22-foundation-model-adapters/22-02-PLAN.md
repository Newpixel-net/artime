---
phase: 22-foundation-model-adapters
plan: 02
type: execute
wave: 2
depends_on: ["22-01"]
files_modified:
  - modules/AppVideoWizard/app/Services/ModelPromptAdapterService.php
  - storage/app/clip_vocab/bpe_simple_vocab_16e6.txt
  - composer.json
autonomous: true
user_setup: []

must_haves:
  truths:
    - "CLIP-based models receive compressed prompts under 77 tokens"
    - "Gemini-based models receive full paragraph prompts without truncation"
    - "Compression preserves subject and action, removes style first"
    - "Token counting uses actual BPE tokenization, not character estimation"
  artifacts:
    - path: "modules/AppVideoWizard/app/Services/ModelPromptAdapterService.php"
      provides: "Model-aware prompt compression with CLIP tokenization"
      exports: ["MODEL_CONFIGS", "adaptPrompt", "countTokens", "compressForClip"]
    - path: "storage/app/clip_vocab/bpe_simple_vocab_16e6.txt"
      provides: "CLIP BPE vocabulary for accurate token counting"
      min_lines: 1000
  key_links:
    - from: "ModelPromptAdapterService.php"
      to: "PromptTemplateLibrary.php"
      via: "uses priority order for intelligent compression"
      pattern: "PromptTemplateLibrary::.*getPriorityOrder"
    - from: "ModelPromptAdapterService.php"
      to: "BPE tokenizer"
      via: "composer dependency for token counting"
      pattern: "BpeTokeniser\\\\Encoder"
---

<objective>
Create model-aware prompt adapter service with CLIP tokenization and intelligent compression.

Purpose: HiDream (RunPod) uses CLIP which silently truncates at 77 tokens. NanoBanana/Pro (Gemini) can handle 4K-8K tokens. This service detects the model and applies appropriate compression, preserving subject/action while trimming style/quality tokens.

Output:
- ModelPromptAdapterService.php with adaptPrompt(), countTokens(), compressForClip()
- CLIP BPE vocabulary file for accurate token counting
- Integration with danny50610/bpe-tokeniser for BPE tokenization

Requirements covered: INF-01
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22-foundation-model-adapters/22-RESEARCH.md
@.planning/phases/22-foundation-model-adapters/22-01-SUMMARY.md
@modules/AppVideoWizard/app/Services/PromptTemplateLibrary.php
@modules/AppVideoWizard/app/Services/ImageGenerationService.php (MODEL_CONFIGS reference)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install BPE Tokenizer and Download CLIP Vocabulary</name>
  <files>composer.json, storage/app/clip_vocab/bpe_simple_vocab_16e6.txt</files>
  <action>
1. **Install PHP BPE tokenizer:**
   ```bash
   composer require danny50610/bpe-tokeniser
   ```

2. **Download CLIP vocabulary file:**
   Create directory: `storage/app/clip_vocab/`
   Download from: `https://openaipublic.blob.core.windows.net/clip/bpe_simple_vocab_16e6.txt`
   Save to: `storage/app/clip_vocab/bpe_simple_vocab_16e6.txt`

3. **Verify vocabulary file:**
   - Should contain 49,152 BPE tokens (one per line)
   - File should be readable by PHP

If the BPE tokenizer library doesn't directly support CLIP vocabulary format, implement a simple fallback:
- Count words (split by space/punctuation)
- Multiply by 1.3 (average tokens per word for English)
- This gives ~85% accuracy, sufficient for compression decisions

Note: CLIP vocabulary uses a simple format - one token per line. The library may need minor adaptation.
  </action>
  <verify>
```bash
# Check composer dependency installed
cd "C:\Users\VoltaPsy\Documents\GitHub\artime" && composer show danny50610/bpe-tokeniser 2>/dev/null || echo "Library not found, checking alternatives..."

# Check vocabulary file exists and has content
ls -la storage/app/clip_vocab/
wc -l storage/app/clip_vocab/bpe_simple_vocab_16e6.txt 2>/dev/null || echo "Vocab file not yet downloaded"
```
  </verify>
  <done>
- BPE tokenizer library installed via Composer
- CLIP vocabulary file exists at storage/app/clip_vocab/bpe_simple_vocab_16e6.txt
- File contains ~49,000 lines (CLIP's vocabulary size)
  </done>
</task>

<task type="auto">
  <name>Task 2: Create ModelPromptAdapterService.php</name>
  <files>modules/AppVideoWizard/app/Services/ModelPromptAdapterService.php</files>
  <action>
Create the model adapter service:

1. **MODEL_CONFIGS constant** - Model-specific configurations:
   ```php
   public const MODEL_CONFIGS = [
       'hidream' => [
           'tokenizer' => 'clip',
           'maxTokens' => 77,
           'truncation' => 'intelligent',
       ],
       'nanobanana' => [
           'tokenizer' => 'gemini',
           'maxTokens' => 4096,
           'truncation' => 'none',
       ],
       'nanobanana-pro' => [
           'tokenizer' => 'gemini',
           'maxTokens' => 8192,
           'truncation' => 'none',
       ],
   ];
   ```

2. **Constructor** - Initialize tokenizer:
   - Try to load CLIP vocabulary from storage/app/clip_vocab/
   - If BPE library works with CLIP vocab, use it
   - If not, use word-based estimation fallback (word_count * 1.3)
   - Log which tokenizer mode is active

3. **adaptPrompt(string $prompt, string $modelId, array $options = []): string**
   - Get model config (default to nanobanana if unknown)
   - If tokenizer is 'gemini', return prompt unchanged
   - If tokenizer is 'clip', call compressForClip()
   - Log: original length, adapted length, was compressed

4. **countTokens(string $text): int**
   - Use BPE encoder if available
   - Fallback: count words, multiply by 1.3, round up
   - Return token count

5. **compressForClip(string $prompt, int $maxTokens): string**
   - Count current tokens
   - If under limit, return unchanged
   - Parse prompt into components using regex patterns:
     - Subject: first sentence up to action verb
     - Action: verb phrases
     - Environment: location/setting descriptions
     - Lighting: light/shadow/color temperature mentions
     - Style: quality markers (8K, photorealistic, etc.)
   - Get priority order from PromptTemplateLibrary (if shot type in options)
   - Remove components from lowest priority until under limit
   - If still over, hard truncate at token boundary

6. **COMPRESSION_PRIORITY constant:**
   ```php
   public const COMPRESSION_PRIORITY = [
       1 => 'subject',      // NEVER remove
       2 => 'action',       // RARELY remove
       3 => 'environment',  // CAN reduce
       4 => 'lighting',     // CAN reduce
       5 => 'atmosphere',   // OFTEN remove
       6 => 'style',        // FIRST to remove
   ];
   ```

7. **getAdaptationStats(string $original, string $adapted, string $modelId): array**
   - Returns: originalTokens, adaptedTokens, wasCompressed, modelConfig

Use dependency injection for PromptTemplateLibrary.
  </action>
  <verify>
```bash
php artisan tinker --execute="
use Modules\AppVideoWizard\Services\ModelPromptAdapterService;
\$adapter = app(ModelPromptAdapterService::class);

// Test with a long prompt
\$longPrompt = 'A beautiful woman with flowing auburn hair stands in a sunlit meadow at golden hour, soft rim lighting, wildflowers swaying, 85mm lens shallow depth of field, cinematic color grading, 8K resolution, photorealistic, ultra detailed skin texture, volumetric light rays';

echo 'Original tokens: ' . \$adapter->countTokens(\$longPrompt) . PHP_EOL;

// Test HiDream adaptation (should compress)
\$hidream = \$adapter->adaptPrompt(\$longPrompt, 'hidream');
echo 'HiDream adapted tokens: ' . \$adapter->countTokens(\$hidream) . PHP_EOL;
echo 'HiDream prompt: ' . \$hidream . PHP_EOL;

// Test NanoBanana adaptation (should not compress)
\$nano = \$adapter->adaptPrompt(\$longPrompt, 'nanobanana');
echo 'NanoBanana unchanged: ' . (\$nano === \$longPrompt ? 'YES' : 'NO') . PHP_EOL;
"
```
  </verify>
  <done>
- adaptPrompt('long prompt', 'hidream') returns prompt under 77 tokens
- adaptPrompt('long prompt', 'nanobanana') returns prompt unchanged
- countTokens() returns reasonable estimates (within 20% of actual)
- Compressed prompts preserve subject, remove style markers
  </done>
</task>

<task type="auto">
  <name>Task 3: Add Comprehensive Tests</name>
  <files>modules/AppVideoWizard/tests/Unit/ModelPromptAdapterServiceTest.php</files>
  <action>
Create unit tests for the adapter service:

**Token Counting Tests:**
- test_count_tokens_returns_integer()
- test_count_tokens_increases_with_length()
- test_count_tokens_handles_empty_string()

**Compression Tests:**
- test_hidream_compresses_long_prompts()
- test_hidream_preserves_short_prompts()
- test_nanobanana_never_compresses()
- test_nanobanana_pro_never_compresses()
- test_unknown_model_defaults_to_nanobanana()

**Priority Tests:**
- test_compression_preserves_subject()
- test_compression_removes_style_first()
- test_compressed_prompt_under_77_tokens()

**Integration Tests:**
- test_adaptation_stats_include_token_counts()
- test_model_configs_match_image_generation_service()

Example test:
```php
public function test_hidream_compresses_long_prompts(): void
{
    $adapter = app(ModelPromptAdapterService::class);

    $longPrompt = str_repeat('beautiful cinematic scene ', 20); // ~100 tokens
    $adapted = $adapter->adaptPrompt($longPrompt, 'hidream');

    $this->assertLessThanOrEqual(77, $adapter->countTokens($adapted));
}

public function test_compression_preserves_subject(): void
{
    $adapter = app(ModelPromptAdapterService::class);

    $prompt = 'A woman stands in a field, golden hour lighting, 8K photorealistic';
    $adapted = $adapter->adaptPrompt($prompt, 'hidream');

    $this->assertStringContainsString('woman', $adapted);
    $this->assertStringContainsString('stands', $adapted);
}
```

Run: `php artisan test --filter=ModelPromptAdapterService`
  </action>
  <verify>
```bash
cd "C:\Users\VoltaPsy\Documents\GitHub\artime" && php artisan test --filter=ModelPromptAdapterService
```
  </verify>
  <done>
- All tests pass
- Compression behavior verified
- Model-specific handling tested
- Edge cases covered
  </done>
</task>

</tasks>

<verification>
```bash
# Verify service is loadable
php artisan tinker --execute="
use Modules\AppVideoWizard\Services\ModelPromptAdapterService;
\$a = app(ModelPromptAdapterService::class);
echo 'Service loaded: YES' . PHP_EOL;
echo 'Model configs: ' . count(ModelPromptAdapterService::MODEL_CONFIGS) . ' models' . PHP_EOL;
"

# Run all adapter tests
php artisan test --filter=ModelPromptAdapterService

# Test compression with real prompt
php artisan tinker --execute="
\$adapter = app(\Modules\AppVideoWizard\Services\ModelPromptAdapterService::class);
\$test = 'A serene woman with delicate features in a sun-drenched garden, 85mm portrait lens with creamy bokeh, golden hour rim lighting at 3500K, soft diffused fill, baroque-inspired framing with subject at left third, photorealistic 8K, film grain';
echo 'Original: ' . \$adapter->countTokens(\$test) . ' tokens' . PHP_EOL;
echo 'HiDream: ' . \$adapter->countTokens(\$adapter->adaptPrompt(\$test, 'hidream')) . ' tokens' . PHP_EOL;
"
```
</verification>

<success_criteria>
1. ModelPromptAdapterService.php exists with MODEL_CONFIGS for hidream, nanobanana, nanobanana-pro
2. countTokens() returns reasonable estimates (not just character/4)
3. adaptPrompt($longPrompt, 'hidream') returns prompt under 77 tokens
4. adaptPrompt($prompt, 'nanobanana') returns prompt unchanged
5. Compressed prompts contain subject/action, remove style markers
6. All unit tests pass
7. CLIP vocabulary file exists (or fallback estimator works)
</success_criteria>

<output>
After completion, create `.planning/phases/22-foundation-model-adapters/22-02-SUMMARY.md`
</output>
