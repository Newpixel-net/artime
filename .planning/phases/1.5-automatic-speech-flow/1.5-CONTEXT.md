# Phase 1.5: Automatic Speech Flow System - Context

**Gathered:** 2026-01-23
**Status:** Ready for planning

<domain>
## Phase Boundary

Remove the Character Intelligence UI section from Step 2 and replace it with an automatic speech flow system. Script text is automatically parsed into speech segments, speakers are auto-linked to Character Bible entries, and all speech data flows through to scenes and shots without user intervention.

**Guiding Principle:** "Automatic, effortless, Hollywood-quality output from button clicks."

</domain>

<decisions>
## Implementation Decisions

### Character Bible Integration
- Auto-create Character Bible entries when new speakers are detected in script
- Auto-link segment speakers to existing Character Bible characters by name matching
- Voice settings (voiceId, voice provider) inherit automatically from Character Bible entry
- If Character Bible has appearance/personality data, it's available for downstream use
- No manual "link speaker" step required - it's automatic

### Script Parsing Trigger
- Parse automatically when AI generates/regenerates script
- Re-parse automatically when user manually edits script text
- No manual "Parse" button - parsing is invisible and instant
- Parser runs in background, updates segments silently
- UI shows results of parsing, not the parsing action itself

### UI Replacement Strategy
- **Remove entirely:** Character Intelligence section (narration style dropdown, character count slider)
- **Replace with:** Read-only "Detection Summary" panel showing:
  - Characters detected (with link to Character Bible)
  - Speech types found (narrator, dialogue, internal, monologue counts)
  - Informational only - no user action required
- Summary appears after script generation, collapses by default
- User can expand to see what was detected, but doesn't need to

### Data Flow Architecture
- **Script** → `SpeechSegmentParser` auto-parses into segments
- **Segments** → Each has `speaker` field, auto-matched to `characterId` in Character Bible
- **Character Bible** → Source of truth for voice settings, appearance, personality
- **Scenes** → Inherit `speechSegments` array with full character data
- **Shots** → Know which segments they contain, inherit `needsLipSync` per segment
- **Video Generation** → Routes to correct model (Minimax vs Multitalk) based on segment type

### Backward Compatibility
- Keep `speechType` field at scene level for legacy projects
- Value `mixed` indicates segment-based (new system)
- Migration: convert old `voiceover.text` to single segment automatically
- `characterIntelligence` property deprecated but kept for old project loading

### Claude's Discretion
- Exact UI design for Detection Summary panel
- Animation/transition when summary appears
- How to handle edge cases (no speakers detected, unknown speaker names)
- Debounce timing for re-parsing on manual edits

</decisions>

<specifics>
## Specific Ideas

- The system should feel "magical" - user types/generates script, everything else happens automatically
- Character Bible is the single source of truth - changes there propagate everywhere
- Detection Summary should be minimal and non-intrusive - users shouldn't feel they need to check it
- The flow should be: Generate Script → See Scenes with Segments → Generate Images → Generate Video
- No intermediate "configure speech" step

</specifics>

<deferred>
## Deferred Ideas

- Voice preview/audition in Character Bible - separate enhancement
- Bulk voice assignment for multiple characters - future UX improvement
- Visual timeline showing segment durations - Phase 6 (UI/UX Polish)

</deferred>

---

*Phase: 1.5-automatic-speech-flow*
*Context gathered: 2026-01-23*
